{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results = 2000000\n",
    "#city_set = [‘New+York’,’Chicago’,’San+Francisco’, ‘Austin’, ‘Seattle’, ‘Los+Angeles’, ‘Philadelphia’, ‘Atlanta’, ‘Dallas’, ‘Pittsburgh’, ‘Portland’, ‘Phoenix’, ‘Denver’, ‘Houston’, ‘Miami’, ‘Washington+DC’, ‘Boulder’]\n",
    "city_set = [\"Canada\"]\n",
    "columns = [\"country\", \"job_title\", \"company_name\", \"location\", \"summary\", \"salary\"]\n",
    "sample_df = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harir\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:177: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "#for city in city_set:\n",
    "for start in range(0, max_results, 10):\n",
    "    ### https://ca.indeed.com/jobs?q=Data+Scientist&l=Canada&radius=25\n",
    "    ### https://ca.indeed.com/jobs?q=technical&l=Canada&sort=date&radius=25\n",
    "    page = requests.get(\"http://ca.indeed.com/jobs?q=Data+Analyst&l=Canada&sort=date&radius=25\" + \"&start=\" + str(start))\n",
    "    time.sleep(1.5)  #ensuring at least 1.5 second between page grabs\n",
    "    soup_temp = BeautifulSoup(page.text, \"lxml\", from_encoding=\"utf-8\")\n",
    "    for div in soup_temp.find_all(name=\"div\", attrs={\"class\":\"row\"}): \n",
    "        #specifying row num for index of job posting in dataframe\n",
    "        num = (len(sample_df) + 1) \n",
    "        #creating an empty list to hold the data for each posting\n",
    "        job_post = [] \n",
    "\n",
    "        #append country name\n",
    "        job_post.append(\"Canada\") \n",
    "\n",
    "        #grabbing job title\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            job_post.append(a[\"title\"])\n",
    "\n",
    "        #grabbing company name\n",
    "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                job_post.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "            for span in sec_try:\n",
    "                job_post.append(span.text.strip())\n",
    "\n",
    "        #grabbing location name\n",
    "        div_two = div.find(name=\"div\",attrs={\"class\":\"sjcl\"})\n",
    "        spans = div_two.find_all(\"span\", attrs={\"class\": \"location\"})\n",
    "        if len(spans) > 0 :\n",
    "            for span in spans:\n",
    "                job_post.append(span.text)\n",
    "        else:\n",
    "            divs = div_two.find_all(\"div\", attrs={\"class\": \"location\"})\n",
    "            if len(divs) > 0:\n",
    "                for d in divs:\n",
    "                    job_post.append(d.text)\n",
    "            else :\n",
    "                job_post.append(\"\")\n",
    "\n",
    "        #grabbing summary text\n",
    "        summary_span = div.find_all(\"div\", attrs={\"class\": \"summary\"})\n",
    "        if len(summary_span) > 0:\n",
    "            for span in summary_span:\n",
    "                if(span.ul):\n",
    "                    if(span.ul.find_all(\"li\")):\n",
    "                        lis = span.ul.find_all(\"li\")\n",
    "                        desc = \"\"\n",
    "                        for li in lis:\n",
    "                            desc = desc+li.text.strip()+'\\n'\n",
    "                        job_post.append(desc)\n",
    "                else:\n",
    "                    job_post.append(\"\")\n",
    "        else:\n",
    "            job_post.append(\"\")\n",
    "\n",
    "        #grabbing salary\n",
    "        salary_span = div.find_all(name=\"span\", attrs={\"class\":\"salaryText\"})\n",
    "        if len(salary_span) > 0:\n",
    "            for span in salary_span:\n",
    "                job_post.append(span.text.strip())\n",
    "        else :\n",
    "            job_post.append(\"Not Found\")\n",
    "\n",
    "        #appending list of job post info to dataframe at index num\n",
    "#         print(job_post)\n",
    "        sample_df.loc[num] = job_post\n",
    "\n",
    "#saving sample_df as a local csv file — define your own local path to save contents \n",
    "sample_df.to_csv(\"Canada_all_roles.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
